# üïµÔ∏è AI in the Real World ‚Äî Judge the Bot

## Assignment Overview
You are now a **Responsible AI Inspector**. Your mission is to investigate real-world AI use cases, spot problems (bias, fairness, transparency, accountability), and suggest improvements.

---

## Case 1: The Hiring Bot Mystery

### What‚Äôs happening:
A company uses an AI hiring assistant to filter job applicants. It keeps rejecting more women who have career gaps.

### What‚Äôs problematic:
- Shows **bias** against women with career breaks.  
- Reduces fairness and diversity in the hiring process.  
- Likely trained on biased historical hiring data.  

### Suggested fix:
- Train AI on **balanced and inclusive data**.  
- Ensure career gaps aren‚Äôt automatically penalized.  
- Add a **human review step** for flagged applications.  

---

## Case 2: The School Proctoring Bot

### What‚Äôs happening:
A school uses an AI proctoring system that flags students as "cheating" based on eye movement.

### What‚Äôs problematic:
- **Neurodivergent, anxious, or visually impaired** students get unfairly flagged.  
- High risk of **false accusations**.  
- Creates stress and reduces trust in the exam system.  

### Suggested fix:
- Use AI as a **support tool, not judge and jury**.  
- Combine eye movement with other signals (e.g., network activity, sound).  
- Keep **human invigilators** in the loop for final judgment.  

---

## ‚ú® Conclusion
Both cases highlight the need for **responsible AI design**. AI must be fair, transparent, and accountable ‚Äî with humans always overseeing critical decisions.

